{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597685421075",
   "display_name": "Python 3.8.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bitcoin (BTC) Price Prediction\n",
    "\n",
    "This notebook was used to analyze the usefullness of Artificial Intelligence and Neural Networks specifically trying to predict the closing price of BTC.\n",
    "\n",
    "In this first cell, there are defined some easily-switchable variables that might help achieving better results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Dropout, LSTM\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "TARGET_COL = 'Close'\n",
    "WINDOW_LEN = 5\n",
    "TEST_SIZE = 0.2\n",
    "ZERO_BASE = True\n",
    "LSTM_NEURONS = 128\n",
    "LSTM_SECOND_NEURONS = 64\n",
    "EPOCHS = 25\n",
    "BATCH_SIZE = 32\n",
    "LOSS = 'mse'\n",
    "DROPOUT = 0.2\n",
    "OPTIMIZER = 'adam'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset \n",
    "I searched for several datasets of Bitcoin (BTC) prices, and the most complete I found have the following columns:\n",
    "> \\[ Date, Open Price, High Price, Low Price, Close Price, Volume \\]\n",
    "\n",
    "The Volume can be found in the currency (USD) or in BTC itself. Some also have Adjusted Close or Weighted Price.\n",
    "\n",
    "The variable _dataset_ is a Pandas' DataFrame object, that holds the pure data coming out of the file, with irrelevant columns dropped.\n",
    "\n",
    "In this particular case, the data have a frequency of 24h (with Date and Adj Close columns dropped):\n",
    "\n",
    "> \\[ \\[ Open, High, Low, Close, Volume \\], ... \\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"BTC-USD.csv\")\n",
    "dataset = dataset.drop(columns=['Date', 'Adj Close'])\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "Next some functions that help in the data processing, division and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the df in train and test datasets\n",
    "# default test_size is 20%\n",
    "def train_test_split(df, test_size=0.2):\n",
    "    split_row = len(df) - int(test_size * len(df))\n",
    "    train_data = df.iloc[:split_row]\n",
    "    test_data = df.iloc[split_row:]\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot both train and test data\n",
    "def line_plot(line1, line2, label1=None, label2=None, title='', lw=2):\n",
    "    fig, ax = plt.subplots(1, figsize=(13, 7))\n",
    "    ax.plot(line1, label=label1, linewidth=lw)\n",
    "    ax.plot(line2, label=label2, linewidth=lw)\n",
    "    ax.set_ylabel('price [USD]', fontsize=14)\n",
    "    ax.set_title(title, fontsize=16)\n",
    "    ax.legend(loc='best', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data normalisation, so they are all in the same scale\n",
    "def normalise_zero_base(df):\n",
    "    return df / df.iloc[0] - 1\n",
    "\n",
    "def normalise_min_max(df):\n",
    "    return (df - df.min()) / (data.max() - df.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrange the dataset to the LSTM layer\n",
    "# returns a 3D array\n",
    "def extract_window_data(df, window_len=5, zero_base=True):\n",
    "    window_data = []\n",
    "    for idx in range(len(df) - window_len):\n",
    "        tmp = df[idx: (idx + window_len)].copy()\n",
    "        if zero_base:\n",
    "            tmp = normalise_zero_base(tmp)\n",
    "        window_data.append(tmp.values)\n",
    "    return np.array(window_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calls all above functions, returning the train and test datasets, ready to use\n",
    "def prepare_data(df, target_col, window_len=5, zero_base=True, test_size=0.2):\n",
    "    train_data, test_data = train_test_split(df, test_size=test_size)\n",
    "    X_train = extract_window_data(train_data, window_len, zero_base)\n",
    "    X_test = extract_window_data(test_data, window_len, zero_base)\n",
    "    y_train = train_data[target_col][window_len:].values\n",
    "    y_test = test_data[target_col][window_len:].values\n",
    "    if zero_base:\n",
    "        y_train = y_train / train_data[target_col][:-window_len].values - 1\n",
    "        y_test = y_test / test_data[target_col][:-window_len].values - 1\n",
    "\n",
    "    return train_data, test_data, X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# builds and returns the NN model\n",
    "def build_lstm_model(input_data, output_size, neurons=100, second_neurons=50, activ_func='linear',\n",
    "                     dropout=0.2, loss='mse', optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(neurons, return_sequences=True, input_shape=(input_data.shape[1], input_data.shape[2])))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(LSTM(second_neurons))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(units=output_size))\n",
    "    model.add(Activation(activ_func))\n",
    "\n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train, test, X_train, X_test, y_train, y_test = prepare_data(dataset, TARGET_COL,window_len=WINDOW_LEN, zero_base=ZERO_BASE, test_size=TEST_SIZE)\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Now it's time to build definitely the model, and train it with the train data we separated from the whole dataset.\n",
    "\n",
    "You will see evolution through epochs of the processing and the loss value, hopefully dropping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = build_lstm_model(X_train, output_size=1, neurons=LSTM_NEURONS,                                  second_neurons=LSTM_SECOND_NEURONS, dropout=DROPOUT,                            loss=LOSS, optimizer=OPTIMIZER)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE,                         verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Here you can analyze the results.\n",
    "The first value is the loss and below a plot is shown with the pairs (True Value, Prediction). The closer the dots to the x=y line, the better, because it means that the model predicted the same value as the real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "targets = test[TARGET_COL][WINDOW_LEN:]\n",
    "preds = model.predict(X_test).squeeze()\n",
    "print(mean_absolute_error(preds, y_test))\n",
    "\n",
    "test_predictions = model.predict(X_test).flatten()\n",
    "\n",
    "plt.scatter(y_test, test_predictions)\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')\n",
    "plt.axis('equal')\n",
    "plt.axis('square')\n",
    "plt.xlim([0,plt.xlim()[1]])\n",
    "plt.ylim([0,plt.ylim()[1]])\n",
    "_ = plt.plot([-100, 100], [-100, 100])\n",
    "\n",
    "#preds = test[TARGET_COL].values[:-WINDOW_LEN] * (preds + 1)\n",
    "#preds = pd.Series(index=targets.index, data=preds)\n",
    "#line_plot(targets, preds, 'actual', 'prediction', lw=3)"
   ]
  }
 ]
}